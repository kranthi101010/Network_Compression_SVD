{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2Y-y1O4SpUO"
      },
      "source": [
        "#Home Work - 3  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGJHCjqmfE8i"
      },
      "source": [
        "## Problem 1: Network Compression Using SVD [2 points]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-BdcB3DxcSPK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow.keras.layers as layers\n",
        "import tensorflow.keras.models as models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ew60aK5CfWxb",
        "outputId": "af4032b5-17e0-4d6c-f97e-ae671ef1821c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "#import mnist dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Juy-Wrn4fm5k"
      },
      "outputs": [],
      "source": [
        "# Normalizing the pixels\n",
        "x_train=x_train.reshape(-1,784)/255.0\n",
        "x_test=x_test.reshape(-1,784)/255.0\n",
        "y_train=tf.keras.utils.to_categorical(y_train,10)\n",
        "y_test=tf.keras.utils.to_categorical(y_test,10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWxD0PnnnBAZ",
        "outputId": "8a29b22f-2d06-4369-ed9f-c4ed64b99929"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "#creating  baseline architecuure\n",
        "model_baseline=models.Sequential()\n",
        "model_baseline.add(layers.Dense(1024,activation='relu',input_shape=(784,)))\n",
        "model_baseline.add(layers.Dense(1024,activation='relu'))\n",
        "model_baseline.add(layers.Dense(1024,activation='relu'))\n",
        "model_baseline.add(layers.Dense(1024,activation='relu'))\n",
        "model_baseline.add(layers.Dense(1024,activation='relu'))\n",
        "model_baseline.add(layers.Dense(10,activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "E2z6oiw8n0d6",
        "outputId": "e607b831-2f46-48a6-bc8c-4af02f1b3453"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">803,840</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,250</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │         \u001b[38;5;34m803,840\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │       \u001b[38;5;34m1,049,600\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │       \u001b[38;5;34m1,049,600\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │       \u001b[38;5;34m1,049,600\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │       \u001b[38;5;34m1,049,600\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │          \u001b[38;5;34m10,250\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,012,490</span> (19.12 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,012,490\u001b[0m (19.12 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,012,490</span> (19.12 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,012,490\u001b[0m (19.12 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_baseline.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBKNcuGXnevL"
      },
      "outputs": [],
      "source": [
        "model_baseline.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbfmKgXRnt4q",
        "outputId": "b07b7d44-76ea-4a7f-b879-c8b1ae45676c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.8840 - loss: 0.3792 - val_accuracy: 0.9671 - val_loss: 0.1176\n",
            "Epoch 2/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9679 - loss: 0.1134 - val_accuracy: 0.9743 - val_loss: 0.0955\n",
            "Epoch 3/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9787 - loss: 0.0812 - val_accuracy: 0.9718 - val_loss: 0.1168\n",
            "Epoch 4/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9825 - loss: 0.0647 - val_accuracy: 0.9700 - val_loss: 0.1135\n",
            "Epoch 5/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9839 - loss: 0.0607 - val_accuracy: 0.9771 - val_loss: 0.1084\n",
            "Epoch 6/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9875 - loss: 0.0472 - val_accuracy: 0.9791 - val_loss: 0.0961\n",
            "Epoch 7/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9905 - loss: 0.0340 - val_accuracy: 0.9802 - val_loss: 0.0886\n",
            "Epoch 8/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9911 - loss: 0.0323 - val_accuracy: 0.9801 - val_loss: 0.0927\n",
            "Epoch 9/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9908 - loss: 0.0332 - val_accuracy: 0.9748 - val_loss: 0.1202\n",
            "Epoch 10/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9912 - loss: 0.0362 - val_accuracy: 0.9792 - val_loss: 0.1007\n",
            "Epoch 11/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9934 - loss: 0.0248 - val_accuracy: 0.9768 - val_loss: 0.1076\n",
            "Epoch 12/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9944 - loss: 0.0226 - val_accuracy: 0.9817 - val_loss: 0.1021\n",
            "Epoch 13/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9946 - loss: 0.0242 - val_accuracy: 0.9835 - val_loss: 0.0917\n",
            "Epoch 14/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9950 - loss: 0.0214 - val_accuracy: 0.9808 - val_loss: 0.1251\n",
            "Epoch 15/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9944 - loss: 0.0234 - val_accuracy: 0.9816 - val_loss: 0.1002\n",
            "Epoch 16/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9955 - loss: 0.0215 - val_accuracy: 0.9801 - val_loss: 0.1296\n",
            "Epoch 17/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9947 - loss: 0.0203 - val_accuracy: 0.9800 - val_loss: 0.1157\n",
            "Epoch 18/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9956 - loss: 0.0190 - val_accuracy: 0.9775 - val_loss: 0.1406\n",
            "Epoch 19/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9959 - loss: 0.0189 - val_accuracy: 0.9824 - val_loss: 0.1152\n",
            "Epoch 20/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9962 - loss: 0.0197 - val_accuracy: 0.9820 - val_loss: 0.1123\n",
            "Epoch 21/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9958 - loss: 0.0206 - val_accuracy: 0.9826 - val_loss: 0.1136\n",
            "Epoch 22/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9972 - loss: 0.0122 - val_accuracy: 0.9814 - val_loss: 0.1215\n",
            "Epoch 23/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9966 - loss: 0.0155 - val_accuracy: 0.9775 - val_loss: 0.1170\n",
            "Epoch 24/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9965 - loss: 0.0168 - val_accuracy: 0.9794 - val_loss: 0.1352\n",
            "Epoch 25/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9968 - loss: 0.0169 - val_accuracy: 0.9846 - val_loss: 0.1199\n",
            "Epoch 26/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9974 - loss: 0.0111 - val_accuracy: 0.9832 - val_loss: 0.1180\n",
            "Epoch 27/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9963 - loss: 0.0169 - val_accuracy: 0.9842 - val_loss: 0.0907\n",
            "Epoch 28/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9971 - loss: 0.0113 - val_accuracy: 0.9804 - val_loss: 0.1709\n",
            "Epoch 29/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9968 - loss: 0.0182 - val_accuracy: 0.9831 - val_loss: 0.1540\n",
            "Epoch 30/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9977 - loss: 0.0125 - val_accuracy: 0.9817 - val_loss: 0.1560\n",
            "Epoch 31/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9971 - loss: 0.0131 - val_accuracy: 0.9828 - val_loss: 0.1463\n",
            "Epoch 32/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9984 - loss: 0.0094 - val_accuracy: 0.9805 - val_loss: 0.1237\n",
            "Epoch 33/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9979 - loss: 0.0100 - val_accuracy: 0.9833 - val_loss: 0.1277\n",
            "Epoch 34/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0045 - val_accuracy: 0.9806 - val_loss: 0.1822\n",
            "Epoch 35/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9968 - loss: 0.0152 - val_accuracy: 0.9809 - val_loss: 0.1947\n",
            "Epoch 36/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9973 - loss: 0.0140 - val_accuracy: 0.9802 - val_loss: 0.1937\n",
            "Epoch 37/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9983 - loss: 0.0100 - val_accuracy: 0.9845 - val_loss: 0.1195\n",
            "Epoch 38/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9982 - loss: 0.0079 - val_accuracy: 0.9842 - val_loss: 0.1806\n",
            "Epoch 39/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9974 - loss: 0.0140 - val_accuracy: 0.9837 - val_loss: 0.1133\n",
            "Epoch 40/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9987 - loss: 0.0048 - val_accuracy: 0.9834 - val_loss: 0.1106\n",
            "Epoch 41/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9986 - loss: 0.0067 - val_accuracy: 0.9811 - val_loss: 0.1864\n",
            "Epoch 42/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9976 - loss: 0.0111 - val_accuracy: 0.9836 - val_loss: 0.1311\n",
            "Epoch 43/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9980 - loss: 0.0100 - val_accuracy: 0.9831 - val_loss: 0.1705\n",
            "Epoch 44/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0036 - val_accuracy: 0.9826 - val_loss: 0.2464\n",
            "Epoch 45/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9979 - loss: 0.0156 - val_accuracy: 0.9816 - val_loss: 0.2417\n",
            "Epoch 46/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9975 - loss: 0.0125 - val_accuracy: 0.9842 - val_loss: 0.1412\n",
            "Epoch 47/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0028 - val_accuracy: 0.9827 - val_loss: 0.1747\n",
            "Epoch 48/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9981 - loss: 0.0095 - val_accuracy: 0.9825 - val_loss: 0.1861\n",
            "Epoch 49/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9983 - loss: 0.0091 - val_accuracy: 0.9849 - val_loss: 0.1694\n",
            "Epoch 50/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9985 - loss: 0.0088 - val_accuracy: 0.9845 - val_loss: 0.1750\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model_baseline.fit(x_train,y_train,epochs=50,batch_size=64,validation_data=(x_test,y_test))\n",
        "model_baseline.save('model_baseline.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tedZXh8ipwrS",
        "outputId": "a99cc9d6-dd12-4bf4-e890-3821bdc107b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9811 - loss: 0.2262\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.17497645318508148, 0.984499990940094]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_baseline.evaluate(x_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8LEVP2qp9Wq"
      },
      "outputs": [],
      "source": [
        "models_list=[]\n",
        "baseline_weights = [layer.get_weights() for layer in model_baseline.layers]\n",
        "svd_weights = [tf.linalg.svd(w[0]) for w in baseline_weights[:-1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgoOIL0At4Ti",
        "outputId": "707fb9c0-9489-487c-df44-abc9ea37e7cb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "D_values=[10,20,50,100,200,\"full\"]\n",
        "for D in D_values:\n",
        "  svd_model = tf.keras.models.load_model('model_baseline.h5')\n",
        "  if D==\"full\":\n",
        "    for i, weights in enumerate(baseline_weights[:-1]):\n",
        "      s,u,v=svd_weights[i]\n",
        "      new_weights = tf.matmul(u, tf.matmul(tf.linalg.diag(s), v, adjoint_b=True))\n",
        "      svd_model.layers[i].set_weights([new_weights, weights[1]])\n",
        "  if D!='full':\n",
        "    for i, weights in enumerate(baseline_weights[:-1]):\n",
        "      s,u,v=svd_weights[i]\n",
        "      u = u[:, :D]\n",
        "      s = s[:D]\n",
        "      v = v[:, :D]\n",
        "      new_weights = tf.matmul(u, tf.matmul(tf.linalg.diag(s), v, adjoint_b=True))\n",
        "      svd_model.layers[i].set_weights([new_weights, weights[1]])\n",
        "  models_list.append(svd_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLom3Ykb28iY",
        "outputId": "75df0e76-de0e-4bf8-e00b-c883e01e703d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0968 - loss: 2.4224\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2953 - loss: 1.8411\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8012 - loss: 0.6914\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9744 - loss: 0.1332\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9795 - loss: 0.1618\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9811 - loss: 0.2262\n"
          ]
        }
      ],
      "source": [
        "values=[]\n",
        "for i in models_list:\n",
        "   k=i.evaluate(x_test,y_test)\n",
        "   values.append(k[1]*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N30YBwfRTLFN",
        "outputId": "3c73f9f0-891c-494e-cdc8-3f75dd12cf4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Value: 10  | Accuracy : 10.019999742507935\n",
            "Value: 20  | Accuracy : 31.209999322891235\n",
            "Value: 50  | Accuracy : 81.20999932289124\n",
            "Value: 100  | Accuracy : 97.87999987602234\n",
            "Value: 200  | Accuracy : 98.22999835014343\n",
            "Value: full  | Accuracy : 98.4499990940094\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for i in range(len(values)):\n",
        "  print(\"Value:\",D_values[i],\" | Accuracy :\",values[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "1BBk-bWqV9mx",
        "outputId": "6cc3ca62-e7b9-4405-8672-28007a87d263"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'D_value')"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(values,D_values)\n",
        "plt.xlabel(\"Accuracy\")\n",
        "plt.ylabel(\"D_value\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8Be-bH6vxXq"
      },
      "source": [
        "## Problem 2: Network Compression Using SVD [2 points]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_BIvffBumFx",
        "outputId": "8a084c71-684e-47b3-be56-590fd709f951"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "#loading the model 20 from the previous list\n",
        "svd_model_20=models_list[1]\n",
        "svd_model.save('model_20.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rdUy7hm3RtA"
      },
      "outputs": [],
      "source": [
        "def generate_fact_model(D_value):\n",
        "  model_20D= tf.keras.models.Sequential()\n",
        "  model_20D.add((tf.keras.layers.Input(shape=(784,))))\n",
        "  svd_model_20_weights = [layer.get_weights() for layer in svd_model_20.layers]\n",
        "  svd_conv_weights = [tf.linalg.svd(w[0]) for w in svd_model_20_weights[:-1]]\n",
        "  for i, weights in enumerate(svd_model_20_weights[:-1]):\n",
        "    s,u,v=svd_conv_weights[i]\n",
        "    u_=u\n",
        "    v_= tf.matmul(tf.linalg.diag(s), v, adjoint_b=True)\n",
        "    layer_weights = tf.matmul(u_,v_)\n",
        "    dense_layer = tf.keras.layers.Dense(1024)\n",
        "    model_20D.add(dense_layer)\n",
        "    dense_layer.set_weights([layer_weights, weights[1]])\n",
        "\n",
        "  model_20D.add(tf.keras.layers.Dense(10,activation='softmax'))\n",
        "  return model_20D\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VabfNq1x8AzR",
        "outputId": "38ac1481-e825-4cf4-e591-26032e313819"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.7573 - loss: 7820.1704 - val_accuracy: 0.8284 - val_loss: 223.3703\n",
            "Epoch 2/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8529 - loss: 124.8829 - val_accuracy: 0.8657 - val_loss: 50.8751\n",
            "Epoch 3/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8621 - loss: 38.8679 - val_accuracy: 0.8598 - val_loss: 19.2548\n",
            "Epoch 4/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8575 - loss: 16.1808 - val_accuracy: 0.8354 - val_loss: 11.5000\n",
            "Epoch 5/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8434 - loss: 15.8846 - val_accuracy: 0.8540 - val_loss: 21.3812\n",
            "Epoch 6/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8366 - loss: 54.5235 - val_accuracy: 0.8572 - val_loss: 8.4881\n",
            "Epoch 7/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8628 - loss: 8.0639 - val_accuracy: 0.8747 - val_loss: 8.3336\n",
            "Epoch 8/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8388 - loss: 21.8807 - val_accuracy: 0.8686 - val_loss: 6.5955\n",
            "Epoch 9/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8650 - loss: 5.1663 - val_accuracy: 0.8779 - val_loss: 3.3213\n",
            "Epoch 10/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8388 - loss: 212.5442 - val_accuracy: 0.8727 - val_loss: 30.7232\n",
            "Epoch 11/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8767 - loss: 18.2921 - val_accuracy: 0.8983 - val_loss: 5.5874\n",
            "Epoch 12/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8764 - loss: 5.0582 - val_accuracy: 0.8660 - val_loss: 3.1281\n",
            "Epoch 13/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8781 - loss: 2.2757 - val_accuracy: 0.8914 - val_loss: 1.2689\n",
            "Epoch 14/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8799 - loss: 1.1679 - val_accuracy: 0.8908 - val_loss: 0.7568\n",
            "Epoch 15/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8709 - loss: 0.9806 - val_accuracy: 0.8556 - val_loss: 2.0688\n",
            "Epoch 16/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8568 - loss: 1.9485 - val_accuracy: 0.8786 - val_loss: 1.4541\n",
            "Epoch 17/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8683 - loss: 1.2956 - val_accuracy: 0.8733 - val_loss: 0.6216\n",
            "Epoch 18/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8715 - loss: 0.8056 - val_accuracy: 0.8270 - val_loss: 3.5129\n",
            "Epoch 19/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8552 - loss: 2.0234 - val_accuracy: 0.9080 - val_loss: 0.3464\n",
            "Epoch 20/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9081 - loss: 0.3313 - val_accuracy: 0.8770 - val_loss: 0.4677\n",
            "Epoch 21/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8439 - loss: 51.3664 - val_accuracy: 0.8798 - val_loss: 1.3191\n",
            "Epoch 22/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8792 - loss: 0.9821 - val_accuracy: 0.8968 - val_loss: 0.4684\n",
            "Epoch 23/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8937 - loss: 0.4475 - val_accuracy: 0.8945 - val_loss: 0.3797\n",
            "Epoch 24/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9018 - loss: 0.3687 - val_accuracy: 0.9078 - val_loss: 0.3438\n",
            "Epoch 25/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9029 - loss: 0.3597 - val_accuracy: 0.8791 - val_loss: 0.4550\n",
            "Epoch 26/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8930 - loss: 0.4133 - val_accuracy: 0.8867 - val_loss: 0.4253\n",
            "Epoch 27/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8895 - loss: 0.4236 - val_accuracy: 0.8809 - val_loss: 0.4312\n",
            "Epoch 28/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8938 - loss: 0.3835 - val_accuracy: 0.8830 - val_loss: 0.4359\n",
            "Epoch 29/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8860 - loss: 0.4159 - val_accuracy: 0.8786 - val_loss: 0.4540\n",
            "Epoch 30/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8823 - loss: 0.4291 - val_accuracy: 0.8740 - val_loss: 0.4189\n",
            "Epoch 31/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8579 - loss: 27.4174 - val_accuracy: 0.8742 - val_loss: 1.7166\n",
            "Epoch 32/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8865 - loss: 1.1033 - val_accuracy: 0.8776 - val_loss: 0.6364\n",
            "Epoch 33/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8977 - loss: 0.4778 - val_accuracy: 0.8982 - val_loss: 0.4086\n",
            "Epoch 34/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9067 - loss: 0.3624 - val_accuracy: 0.9057 - val_loss: 0.3794\n",
            "Epoch 35/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9064 - loss: 0.3475 - val_accuracy: 0.9041 - val_loss: 0.3836\n",
            "Epoch 36/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9055 - loss: 0.3519 - val_accuracy: 0.8943 - val_loss: 0.3950\n",
            "Epoch 37/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9038 - loss: 0.3587 - val_accuracy: 0.9010 - val_loss: 0.3699\n",
            "Epoch 38/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9093 - loss: 0.3320 - val_accuracy: 0.8935 - val_loss: 0.3869\n",
            "Epoch 39/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9047 - loss: 0.3430 - val_accuracy: 0.8837 - val_loss: 0.3939\n",
            "Epoch 40/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9049 - loss: 0.3364 - val_accuracy: 0.8913 - val_loss: 0.4018\n",
            "Epoch 41/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8976 - loss: 0.3637 - val_accuracy: 0.8825 - val_loss: 0.4090\n",
            "Epoch 42/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8663 - loss: 27.4750 - val_accuracy: 0.8913 - val_loss: 1.7065\n",
            "Epoch 43/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8914 - loss: 1.1326 - val_accuracy: 0.8996 - val_loss: 0.5494\n",
            "Epoch 44/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9033 - loss: 0.4506 - val_accuracy: 0.9050 - val_loss: 0.3912\n",
            "Epoch 45/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9097 - loss: 0.3496 - val_accuracy: 0.9150 - val_loss: 0.3476\n",
            "Epoch 46/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.3302 - val_accuracy: 0.9032 - val_loss: 0.3753\n",
            "Epoch 47/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9138 - loss: 0.3342 - val_accuracy: 0.9132 - val_loss: 0.3360\n",
            "Epoch 48/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.3244 - val_accuracy: 0.9039 - val_loss: 0.3491\n",
            "Epoch 49/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 0.3189 - val_accuracy: 0.8994 - val_loss: 0.3716\n",
            "Epoch 50/50\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9096 - loss: 0.3200 - val_accuracy: 0.9110 - val_loss: 0.3224\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model_20D=generate_fact_model(20)\n",
        "model_20D.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model_20D.fit(x_train,y_train,epochs=50,batch_size=64,validation_data=(x_test,y_test))\n",
        "model_20D.save('model_20D_updated.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHDoKMoD8foG",
        "outputId": "84b1cbf4-b58a-4f3e-9fa7-50934146bb5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8949 - loss: 0.3675\n"
          ]
        }
      ],
      "source": [
        "k=model_20D.evaluate(x_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYU3SF22azxH",
        "outputId": "de9b0b10-157d-463c-a220-4d020c9c0861"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of Model_20D : 91.10000133514404\n"
          ]
        }
      ],
      "source": [
        "print(\"Accuracy of Model_20D :\",k[1]*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JR8wxBvlHmI7"
      },
      "source": [
        "we got the test accuracy of 91.1% which is a very good improvement from the 32% accruacy before the factorization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8Uai34iH0vD"
      },
      "source": [
        "## Problem 3: Network Compression Using SVD [3 points]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pT-9FB_G4O5S"
      },
      "outputs": [],
      "source": [
        "svd_model_epochwise=tf.keras.models.Sequential()\n",
        "svd_model_epochwise.add(tf.keras.layers.Input(shape=(784,)))\n",
        "svd_model_epochwise.add(tf.keras.layers.Dense(1024,activation='relu'))\n",
        "svd_model_epochwise.add(tf.keras.layers.Dense(1024,activation='relu'))\n",
        "svd_model_epochwise.add(tf.keras.layers.Dense(1024,activation='relu'))\n",
        "svd_model_epochwise.add(tf.keras.layers.Dense(1024,activation='relu'))\n",
        "svd_model_epochwise.add(tf.keras.layers.Dense(1024,activation='relu'))\n",
        "svd_model_epochwise.add(tf.keras.layers.Dense(10,activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHn77Cs4Hgfj",
        "outputId": "a42ab650-266b-4105-a0c3-6de64a0990b1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "baseline_weights = tf.keras.models.load_model('model_baseline.h5').get_weights()\n",
        "svd_model_epochwise.set_weights(baseline_weights)\n",
        "svd_model_epochwise.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcsHV4fY4DZF",
        "outputId": "793cd455-1ec9-49ab-987b-b1590706a296"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 46904 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x7cc764bf70a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 46905 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x7cc764bf70a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9565 - loss: 0.2202\n",
            "Epoch 2/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9673 - loss: 0.1614\n",
            "Epoch 3/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9700 - loss: 0.1387\n",
            "Epoch 4/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9729 - loss: 0.1336\n",
            "Epoch 5/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9735 - loss: 0.1277\n",
            "Epoch 6/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9744 - loss: 0.1414\n",
            "Epoch 7/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9752 - loss: 0.1426\n",
            "Epoch 8/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9746 - loss: 0.1506\n",
            "Epoch 9/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9744 - loss: 0.1434\n",
            "Epoch 10/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9762 - loss: 0.1468\n",
            "Epoch 11/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9756 - loss: 0.1868\n",
            "Epoch 12/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9757 - loss: 0.1490\n",
            "Epoch 13/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9773 - loss: 0.1461\n",
            "Epoch 14/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9767 - loss: 0.1873\n",
            "Epoch 15/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9767 - loss: 0.1833\n",
            "Epoch 16/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9765 - loss: 0.1938\n",
            "Epoch 17/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9758 - loss: 0.2077\n",
            "Epoch 18/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9764 - loss: 0.2086\n",
            "Epoch 19/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9759 - loss: 0.2137\n",
            "Epoch 20/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9744 - loss: 0.2080\n"
          ]
        }
      ],
      "source": [
        "epochs = 20\n",
        "batch_size = 1024\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  print(f'Epoch {epoch + 1}/{epochs}')\n",
        "  for i in range(0, x_train.shape[0], batch_size):\n",
        "    x_batch = x_train[i:i + batch_size]\n",
        "    y_batch = y_train[i:i + batch_size]\n",
        "\n",
        "    for layer in svd_model_epochwise.layers[:-1]:\n",
        "      weights = layer.get_weights()\n",
        "      s, u, v = tf.linalg.svd(weights[0])\n",
        "      u = u[:, :20]\n",
        "      s = s[:20]\n",
        "      v = v[:, :20]\n",
        "      weights[0] = tf.matmul(u, tf.matmul(tf.linalg.diag(s), v, adjoint_b=True))\n",
        "      layer.set_weights(weights)\n",
        "\n",
        "    batch_loss, batch_accuracy = svd_model_epochwise.train_on_batch(x_batch, y_batch)\n",
        "  loss, accuracy = svd_model_epochwise.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Neby4STR92ut",
        "outputId": "124dcafc-ca62-48b5-abbe-ae9307e399e9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "svd_model_epochwise.save('model_epochwise.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i86utwMv98Sh",
        "outputId": "fc878335-12c1-43ca-ab3a-178ca2646835"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9744 - loss: 0.2080\n",
            "Test accuracy: 97.82%\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_accuracy = svd_model_epochwise.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy: {test_accuracy * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSkvpBt34Ert"
      },
      "source": [
        "The accuracy is very close to 97% and it is almost same as the base line accuracy."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
